"""anne-bonner-tutorial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HHqlNF9yHXvDF6fCfZjhMzbvgDP-Jo89

Install modules
"""

# !pip install tensorflow
# !pip install tensorflow-gpu
# !pip install keras

"""Import Modules"""

import keras
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler

"""Check Versions"""

print(tf.__version__)
print(keras.__version__)
print(np.__version__)
print(pd.__version__)

"""Download dataset"""

# !wget -cq https://raw.githubusercontent.com/D-Bhatta/Data-Cleaning-Beginner/master/anne-bonner-tutorial/my_data.csv

"""Check for GPU"""

device_name = tf.test.gpu_device_name()
# if device_name != '/device:GPU:0':
# raise SystemError("GPU device not found")
# print(f'Found GPU at: {device_name}')

"""Load data"""

dataset = pd.read_csv("my_data.csv")
dataset

"""Create independent dataset partition"""

x = dataset.iloc[:, :-1].values
x

"""Create dependent dataset partition"""

y = dataset.iloc[:, -1].values
y

"""Replace missing data wtih SimpleImputer"""

imputer = SimpleImputer(missing_values=np.nan, strategy="most_frequent")
imputer = imputer.fit(x[:, 1:3])

"""Apply imputer transform to column of data"""

x[:, 1:3] = imputer.transform(x[:, 1:3])
x

"""Encode categorical data as ratios"""

labelencoder_x = LabelEncoder()
x[:, 0] = labelencoder_x.fit_transform(x[:, 0])
x

"""Collect column of labelled categorical data"""

x_labeled = x[:, 0]
x_labeled

"""Encode column of ratios into multiple columns of binary data"""

onehotencoder_x = OneHotEncoder(handle_unknown="ignore")
x_labeled = x_labeled.reshape(-1, 1)
x_encoded = onehotencoder_x.fit_transform(x_labeled)
x_encoded = x_encoded.toarray()
x_encoded

"""Concatenate encoded rows onto x"""

x = np.concatenate([x_encoded, x[:, 1:]], axis=1)
x

"""Create scaler object"""

sc_x = StandardScaler()

"""Copy column to scale into temp variable"""

x_sc = x[:, 3:]
x_sc

"""Apply the scaler"""

x_sc = sc_x.fit_transform(x_sc)
x_sc

"""Concatenate scaled data to rest of the dataset"""

x = np.concatenate([x[:, :3], x_sc], axis=1)
x
